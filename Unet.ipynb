{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ULGH5y5qkFr",
        "outputId": "0e2e880e-edf6-46b5-9890-725139946797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ihuTkuRrQuu"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgB0Xvqws-4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e225c5f-6564-45ee-979f-07c6a031fd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n",
            "38\n"
          ]
        }
      ],
      "source": [
        "print(len('/content/drive/MyDrive/Lung_Seg/Model_Xrays/'))\n",
        "print(len('/content/drive/MyDrive/Lung_Seg/Masks/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2BAsz91slUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badcb5ab-9456-4548-bfc0-35b9e05ffbbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JPCLN002.png',\n",
              " 'JPCLN001.png',\n",
              " 'JPCLN003.png',\n",
              " 'JPCLN004.png',\n",
              " 'JPCLN005.png',\n",
              " 'JPCLN006.png',\n",
              " 'JPCLN007.png',\n",
              " 'JPCLN008.png',\n",
              " 'JPCLN009.png',\n",
              " 'JPCLN010.png',\n",
              " 'JPCLN011.png',\n",
              " 'JPCLN012.png',\n",
              " 'JPCLN013.png',\n",
              " 'JPCLN014.png',\n",
              " 'JPCLN015.png',\n",
              " 'JPCLN016.png',\n",
              " 'JPCLN017.png',\n",
              " 'JPCLN018.png',\n",
              " 'JPCLN019.png',\n",
              " 'JPCLN020.png',\n",
              " 'JPCLN021.png',\n",
              " 'JPCLN022.png',\n",
              " 'JPCLN023.png',\n",
              " 'JPCLN024.png',\n",
              " 'JPCLN025.png',\n",
              " 'JPCLN026.png',\n",
              " 'JPCLN027.png',\n",
              " 'JPCLN028.png',\n",
              " 'JPCLN029.png',\n",
              " 'JPCLN030.png',\n",
              " 'JPCLN031.png',\n",
              " 'JPCLN032.png',\n",
              " 'JPCLN033.png',\n",
              " 'JPCLN034.png',\n",
              " 'JPCLN035.png',\n",
              " 'JPCLN036.png',\n",
              " 'JPCLN037.png',\n",
              " 'JPCLN038.png',\n",
              " 'JPCLN039.png',\n",
              " 'JPCLN040.png',\n",
              " 'JPCLN041.png',\n",
              " 'JPCLN042.png',\n",
              " 'JPCLN043.png',\n",
              " 'JPCLN044.png',\n",
              " 'JPCLN045.png',\n",
              " 'JPCLN046.png',\n",
              " 'JPCLN047.png',\n",
              " 'JPCLN048.png',\n",
              " 'JPCLN049.png',\n",
              " 'JPCLN050.png',\n",
              " 'JPCLN051.png',\n",
              " 'JPCLN052.png',\n",
              " 'JPCLN053.png',\n",
              " 'JPCLN054.png',\n",
              " 'JPCLN055.png',\n",
              " 'JPCLN056.png',\n",
              " 'JPCLN057.png',\n",
              " 'JPCLN058.png',\n",
              " 'JPCLN059.png',\n",
              " 'JPCLN060.png',\n",
              " 'JPCLN061.png',\n",
              " 'JPCLN062.png',\n",
              " 'JPCLN063.png',\n",
              " 'JPCLN064.png',\n",
              " 'JPCLN065.png',\n",
              " 'JPCLN066.png',\n",
              " 'JPCLN067.png',\n",
              " 'JPCLN068.png',\n",
              " 'JPCLN069.png',\n",
              " 'JPCLN070.png',\n",
              " 'JPCLN071.png',\n",
              " 'JPCLN072.png',\n",
              " 'JPCLN073.png',\n",
              " 'JPCLN074.png',\n",
              " 'JPCLN075.png',\n",
              " 'JPCLN076.png',\n",
              " 'JPCLN077.png',\n",
              " 'JPCLN078.png',\n",
              " 'JPCLN079.png',\n",
              " 'JPCLN080.png',\n",
              " 'JPCLN081.png',\n",
              " 'JPCLN082.png',\n",
              " 'JPCLN083.png',\n",
              " 'JPCLN084.png',\n",
              " 'JPCLN085.png',\n",
              " 'JPCLN086.png',\n",
              " 'JPCLN087.png',\n",
              " 'JPCLN088.png',\n",
              " 'JPCLN089.png',\n",
              " 'JPCLN090.png',\n",
              " 'JPCLN091.png',\n",
              " 'JPCLN092.png',\n",
              " 'JPCLN093.png',\n",
              " 'JPCLN094.png',\n",
              " 'JPCLN095.png',\n",
              " 'JPCLN096.png',\n",
              " 'JPCLN097.png',\n",
              " 'JPCLN098.png',\n",
              " 'JPCLN099.png',\n",
              " 'JPCLN100.png',\n",
              " 'JPCLN101.png',\n",
              " 'JPCLN102.png',\n",
              " 'JPCLN103.png',\n",
              " 'JPCLN104.png',\n",
              " 'JPCLN105.png',\n",
              " 'JPCLN106.png',\n",
              " 'JPCLN107.png',\n",
              " 'JPCLN108.png',\n",
              " 'JPCLN109.png',\n",
              " 'JPCLN110.png',\n",
              " 'JPCLN111.png',\n",
              " 'JPCLN112.png',\n",
              " 'JPCLN113.png',\n",
              " 'JPCLN114.png',\n",
              " 'JPCLN115.png',\n",
              " 'JPCLN116.png',\n",
              " 'JPCLN117.png',\n",
              " 'JPCLN118.png',\n",
              " 'JPCLN119.png',\n",
              " 'JPCLN120.png',\n",
              " 'JPCLN121.png',\n",
              " 'JPCLN122.png',\n",
              " 'JPCLN123.png',\n",
              " 'JPCLN124.png',\n",
              " 'JPCLN125.png',\n",
              " 'JPCLN126.png',\n",
              " 'JPCLN127.png',\n",
              " 'JPCLN128.png',\n",
              " 'JPCLN129.png',\n",
              " 'JPCLN130.png',\n",
              " 'JPCLN131.png',\n",
              " 'JPCLN132.png',\n",
              " 'JPCLN133.png',\n",
              " 'JPCLN134.png',\n",
              " 'JPCLN135.png',\n",
              " 'JPCLN136.png',\n",
              " 'JPCLN137.png',\n",
              " 'JPCLN138.png',\n",
              " 'JPCLN139.png',\n",
              " 'JPCLN140.png',\n",
              " 'JPCLN141.png',\n",
              " 'JPCLN142.png',\n",
              " 'JPCLN143.png',\n",
              " 'JPCLN144.png',\n",
              " 'JPCLN145.png',\n",
              " 'JPCLN146.png',\n",
              " 'JPCLN147.png',\n",
              " 'JPCLN148.png',\n",
              " 'JPCLN149.png',\n",
              " 'JPCLN150.png',\n",
              " 'JPCLN151.png',\n",
              " 'JPCLN152.png',\n",
              " 'JPCLN153.png',\n",
              " 'JPCLN154.png',\n",
              " 'JPCNN001.png',\n",
              " 'JPCNN002.png',\n",
              " 'JPCNN003.png',\n",
              " 'JPCNN004.png',\n",
              " 'JPCNN005.png',\n",
              " 'JPCNN006.png',\n",
              " 'JPCNN007.png',\n",
              " 'JPCNN008.png',\n",
              " 'JPCNN009.png',\n",
              " 'JPCNN010.png',\n",
              " 'JPCNN011.png',\n",
              " 'JPCNN012.png',\n",
              " 'JPCNN013.png',\n",
              " 'JPCNN014.png',\n",
              " 'JPCNN015.png',\n",
              " 'JPCNN016.png',\n",
              " 'JPCNN017.png',\n",
              " 'JPCNN018.png',\n",
              " 'JPCNN019.png',\n",
              " 'JPCNN020.png',\n",
              " 'JPCNN021.png',\n",
              " 'JPCNN022.png',\n",
              " 'JPCNN023.png',\n",
              " 'JPCNN024.png',\n",
              " 'JPCNN025.png',\n",
              " 'JPCNN026.png',\n",
              " 'JPCNN027.png',\n",
              " 'JPCNN028.png',\n",
              " 'JPCNN029.png',\n",
              " 'JPCNN030.png',\n",
              " 'JPCNN031.png',\n",
              " 'JPCNN032.png',\n",
              " 'JPCNN033.png',\n",
              " 'JPCNN034.png',\n",
              " 'JPCNN035.png',\n",
              " 'JPCNN036.png',\n",
              " 'JPCNN037.png',\n",
              " 'JPCNN038.png',\n",
              " 'JPCNN039.png',\n",
              " 'JPCNN040.png',\n",
              " 'JPCNN041.png',\n",
              " 'JPCNN042.png',\n",
              " 'JPCNN043.png',\n",
              " 'JPCNN044.png',\n",
              " 'JPCNN045.png',\n",
              " 'JPCNN046.png',\n",
              " 'JPCNN047.png',\n",
              " 'JPCNN048.png',\n",
              " 'JPCNN049.png',\n",
              " 'JPCNN050.png',\n",
              " 'JPCNN051.png',\n",
              " 'JPCNN052.png',\n",
              " 'JPCNN053.png',\n",
              " 'JPCNN054.png',\n",
              " 'JPCNN055.png',\n",
              " 'JPCNN056.png',\n",
              " 'JPCNN057.png',\n",
              " 'JPCNN058.png',\n",
              " 'JPCNN059.png',\n",
              " 'JPCNN060.png',\n",
              " 'JPCNN061.png',\n",
              " 'JPCNN062.png',\n",
              " 'JPCNN063.png',\n",
              " 'JPCNN064.png',\n",
              " 'JPCNN065.png',\n",
              " 'JPCNN066.png',\n",
              " 'JPCNN067.png',\n",
              " 'JPCNN068.png',\n",
              " 'JPCNN069.png',\n",
              " 'JPCNN070.png',\n",
              " 'JPCNN071.png',\n",
              " 'JPCNN072.png',\n",
              " 'JPCNN073.png',\n",
              " 'JPCNN074.png',\n",
              " 'JPCNN075.png',\n",
              " 'JPCNN076.png',\n",
              " 'JPCNN077.png',\n",
              " 'JPCNN078.png',\n",
              " 'JPCNN079.png',\n",
              " 'JPCNN080.png',\n",
              " 'JPCNN081.png',\n",
              " 'JPCNN082.png',\n",
              " 'JPCNN083.png',\n",
              " 'JPCNN084.png',\n",
              " 'JPCNN085.png',\n",
              " 'JPCNN086.png',\n",
              " 'JPCNN087.png',\n",
              " 'JPCNN088.png',\n",
              " 'JPCNN089.png',\n",
              " 'JPCNN090.png',\n",
              " 'JPCNN091.png',\n",
              " 'JPCNN092.png',\n",
              " 'JPCNN093.png',\n",
              " 'MCUCXR_0001_0.png',\n",
              " 'MCUCXR_0002_0.png',\n",
              " 'MCUCXR_0003_0.png',\n",
              " 'MCUCXR_0004_0.png',\n",
              " 'MCUCXR_0005_0.png',\n",
              " 'MCUCXR_0006_0.png',\n",
              " 'MCUCXR_0008_0.png',\n",
              " 'MCUCXR_0011_0.png',\n",
              " 'MCUCXR_0013_0.png',\n",
              " 'MCUCXR_0015_0.png',\n",
              " 'MCUCXR_0016_0.png',\n",
              " 'MCUCXR_0017_0.png',\n",
              " 'MCUCXR_0019_0.png',\n",
              " 'MCUCXR_0020_0.png',\n",
              " 'MCUCXR_0021_0.png',\n",
              " 'MCUCXR_0023_0.png',\n",
              " 'MCUCXR_0022_0.png',\n",
              " 'MCUCXR_0024_0.png',\n",
              " 'MCUCXR_0026_0.png',\n",
              " 'MCUCXR_0028_0.png',\n",
              " 'MCUCXR_0027_0.png',\n",
              " 'MCUCXR_0029_0.png',\n",
              " 'MCUCXR_0030_0.png',\n",
              " 'MCUCXR_0031_0.png',\n",
              " 'MCUCXR_0035_0.png',\n",
              " 'MCUCXR_0038_0.png',\n",
              " 'MCUCXR_0040_0.png',\n",
              " 'MCUCXR_0041_0.png',\n",
              " 'MCUCXR_0042_0.png',\n",
              " 'MCUCXR_0044_0.png',\n",
              " 'MCUCXR_0043_0.png',\n",
              " 'MCUCXR_0046_0.png',\n",
              " 'MCUCXR_0045_0.png',\n",
              " 'MCUCXR_0047_0.png',\n",
              " 'MCUCXR_0048_0.png',\n",
              " 'MCUCXR_0049_0.png',\n",
              " 'MCUCXR_0051_0.png',\n",
              " 'MCUCXR_0052_0.png',\n",
              " 'MCUCXR_0053_0.png',\n",
              " 'MCUCXR_0054_0.png',\n",
              " 'MCUCXR_0055_0.png',\n",
              " 'MCUCXR_0056_0.png',\n",
              " 'MCUCXR_0057_0.png',\n",
              " 'MCUCXR_0058_0.png',\n",
              " 'MCUCXR_0059_0.png',\n",
              " 'MCUCXR_0060_0.png',\n",
              " 'MCUCXR_0061_0.png',\n",
              " 'MCUCXR_0063_0.png',\n",
              " 'MCUCXR_0062_0.png',\n",
              " 'MCUCXR_0064_0.png',\n",
              " 'MCUCXR_0069_0.png',\n",
              " 'MCUCXR_0068_0.png',\n",
              " 'MCUCXR_0070_0.png',\n",
              " 'MCUCXR_0071_0.png',\n",
              " 'MCUCXR_0072_0.png',\n",
              " 'MCUCXR_0074_0.png',\n",
              " 'MCUCXR_0104_1.png',\n",
              " 'MCUCXR_0075_0.png',\n",
              " 'MCUCXR_0108_1.png',\n",
              " 'MCUCXR_0077_0.png',\n",
              " 'MCUCXR_0113_1.png',\n",
              " 'MCUCXR_0117_1.png',\n",
              " 'MCUCXR_0080_0.png',\n",
              " 'MCUCXR_0079_0.png',\n",
              " 'MCUCXR_0081_0.png',\n",
              " 'MCUCXR_0082_0.png',\n",
              " 'MCUCXR_0083_0.png',\n",
              " 'MCUCXR_0084_0.png',\n",
              " 'MCUCXR_0126_1.png',\n",
              " 'MCUCXR_0085_0.png',\n",
              " 'MCUCXR_0086_0.png',\n",
              " 'MCUCXR_0089_0.png',\n",
              " 'MCUCXR_0087_0.png',\n",
              " 'MCUCXR_0090_0.png',\n",
              " 'MCUCXR_0091_0.png',\n",
              " 'MCUCXR_0140_1.png',\n",
              " 'MCUCXR_0092_0.png',\n",
              " 'MCUCXR_0141_1.png',\n",
              " 'MCUCXR_0094_0.png',\n",
              " 'MCUCXR_0142_1.png',\n",
              " 'MCUCXR_0095_0.png',\n",
              " 'MCUCXR_0096_0.png',\n",
              " 'MCUCXR_0144_1.png',\n",
              " 'MCUCXR_0097_0.png',\n",
              " 'MCUCXR_0099_0.png',\n",
              " 'MCUCXR_0150_1.png',\n",
              " 'MCUCXR_0101_0.png',\n",
              " 'MCUCXR_0100_0.png',\n",
              " 'MCUCXR_0102_0.png',\n",
              " 'MCUCXR_0103_0.png',\n",
              " 'MCUCXR_0162_1.png',\n",
              " 'MCUCXR_0166_1.png',\n",
              " 'MCUCXR_0170_1.png',\n",
              " 'MCUCXR_0173_1.png',\n",
              " 'MCUCXR_0182_1.png',\n",
              " 'MCUCXR_0188_1.png',\n",
              " 'MCUCXR_0194_1.png',\n",
              " 'MCUCXR_0195_1.png',\n",
              " 'MCUCXR_0196_1.png',\n",
              " 'MCUCXR_0203_1.png',\n",
              " 'MCUCXR_0213_1.png',\n",
              " 'MCUCXR_0218_1.png',\n",
              " 'MCUCXR_0223_1.png',\n",
              " 'MCUCXR_0228_1.png',\n",
              " 'MCUCXR_0243_1.png',\n",
              " 'MCUCXR_0251_1.png',\n",
              " 'MCUCXR_0253_1.png',\n",
              " 'MCUCXR_0254_1.png',\n",
              " 'MCUCXR_0255_1.png',\n",
              " 'MCUCXR_0258_1.png',\n",
              " 'MCUCXR_0264_1.png',\n",
              " 'MCUCXR_0266_1.png',\n",
              " 'MCUCXR_0275_1.png',\n",
              " 'MCUCXR_0282_1.png',\n",
              " 'MCUCXR_0289_1.png',\n",
              " 'MCUCXR_0294_1.png',\n",
              " 'MCUCXR_0301_1.png',\n",
              " 'MCUCXR_0309_1.png',\n",
              " 'MCUCXR_0311_1.png',\n",
              " 'MCUCXR_0313_1.png',\n",
              " 'MCUCXR_0316_1.png',\n",
              " 'MCUCXR_0331_1.png',\n",
              " 'MCUCXR_0334_1.png',\n",
              " 'MCUCXR_0338_1.png',\n",
              " 'MCUCXR_0348_1.png',\n",
              " 'MCUCXR_0350_1.png',\n",
              " 'MCUCXR_0352_1.png',\n",
              " 'MCUCXR_0354_1.png',\n",
              " 'MCUCXR_0362_1.png',\n",
              " 'MCUCXR_0367_1.png',\n",
              " 'MCUCXR_0369_1.png',\n",
              " 'MCUCXR_0372_1.png',\n",
              " 'MCUCXR_0375_1.png',\n",
              " 'MCUCXR_0383_1.png',\n",
              " 'MCUCXR_0387_1.png',\n",
              " 'MCUCXR_0390_1.png',\n",
              " 'MCUCXR_0393_1.png',\n",
              " 'MCUCXR_0399_1.png',\n",
              " 'CHNCXR_0001_0.png',\n",
              " 'CHNCXR_0002_0.png',\n",
              " 'CHNCXR_0003_0.png',\n",
              " 'CHNCXR_0004_0.png',\n",
              " 'CHNCXR_0005_0.png',\n",
              " 'CHNCXR_0006_0.png',\n",
              " 'CHNCXR_0007_0.png',\n",
              " 'CHNCXR_0008_0.png',\n",
              " 'CHNCXR_0009_0.png',\n",
              " 'CHNCXR_0010_0.png',\n",
              " 'CHNCXR_0011_0.png',\n",
              " 'CHNCXR_0012_0.png',\n",
              " 'CHNCXR_0013_0.png',\n",
              " 'CHNCXR_0014_0.png',\n",
              " 'CHNCXR_0015_0.png',\n",
              " 'CHNCXR_0016_0.png',\n",
              " 'CHNCXR_0017_0.png',\n",
              " 'CHNCXR_0018_0.png',\n",
              " 'CHNCXR_0019_0.png',\n",
              " 'CHNCXR_0020_0.png',\n",
              " 'CHNCXR_0021_0.png',\n",
              " 'CHNCXR_0022_0.png',\n",
              " 'CHNCXR_0023_0.png',\n",
              " 'CHNCXR_0024_0.png',\n",
              " 'CHNCXR_0026_0.png',\n",
              " 'CHNCXR_0027_0.png',\n",
              " 'CHNCXR_0028_0.png',\n",
              " 'CHNCXR_0029_0.png',\n",
              " 'CHNCXR_0030_0.png',\n",
              " 'CHNCXR_0031_0.png',\n",
              " 'CHNCXR_0032_0.png',\n",
              " 'CHNCXR_0033_0.png',\n",
              " 'CHNCXR_0034_0.png',\n",
              " 'CHNCXR_0035_0.png',\n",
              " 'CHNCXR_0041_0.png',\n",
              " 'CHNCXR_0042_0.png',\n",
              " 'CHNCXR_0043_0.png',\n",
              " 'CHNCXR_0044_0.png',\n",
              " 'CHNCXR_0045_0.png',\n",
              " 'CHNCXR_0046_0.png',\n",
              " 'CHNCXR_0047_0.png',\n",
              " 'CHNCXR_0048_0.png',\n",
              " 'CHNCXR_0049_0.png',\n",
              " 'CHNCXR_0050_0.png',\n",
              " 'CHNCXR_0051_0.png',\n",
              " 'CHNCXR_0052_0.png',\n",
              " 'CHNCXR_0053_0.png',\n",
              " 'CHNCXR_0054_0.png',\n",
              " 'CHNCXR_0055_0.png',\n",
              " 'CHNCXR_0056_0.png',\n",
              " 'CHNCXR_0057_0.png',\n",
              " 'CHNCXR_0058_0.png',\n",
              " 'CHNCXR_0059_0.png',\n",
              " 'CHNCXR_0060_0.png',\n",
              " 'CHNCXR_0061_0.png',\n",
              " 'CHNCXR_0062_0.png',\n",
              " 'CHNCXR_0063_0.png',\n",
              " 'CHNCXR_0064_0.png',\n",
              " 'CHNCXR_0066_0.png',\n",
              " 'CHNCXR_0067_0.png',\n",
              " 'CHNCXR_0068_0.png',\n",
              " 'CHNCXR_0069_0.png',\n",
              " 'CHNCXR_0070_0.png',\n",
              " 'CHNCXR_0071_0.png',\n",
              " 'CHNCXR_0072_0.png',\n",
              " 'CHNCXR_0073_0.png',\n",
              " 'CHNCXR_0074_0.png',\n",
              " 'CHNCXR_0075_0.png',\n",
              " 'CHNCXR_0076_0.png',\n",
              " 'CHNCXR_0077_0.png',\n",
              " 'CHNCXR_0078_0.png',\n",
              " 'CHNCXR_0079_0.png',\n",
              " 'CHNCXR_0080_0.png',\n",
              " 'CHNCXR_0081_0.png',\n",
              " 'CHNCXR_0082_0.png',\n",
              " 'CHNCXR_0083_0.png',\n",
              " 'CHNCXR_0084_0.png',\n",
              " 'CHNCXR_0085_0.png',\n",
              " 'CHNCXR_0086_0.png',\n",
              " 'CHNCXR_0087_0.png',\n",
              " 'CHNCXR_0088_0.png',\n",
              " 'CHNCXR_0089_0.png',\n",
              " 'CHNCXR_0090_0.png',\n",
              " 'CHNCXR_0091_0.png',\n",
              " 'CHNCXR_0092_0.png',\n",
              " 'CHNCXR_0093_0.png',\n",
              " 'CHNCXR_0094_0.png',\n",
              " 'CHNCXR_0095_0.png',\n",
              " 'CHNCXR_0096_0.png',\n",
              " 'CHNCXR_0097_0.png',\n",
              " 'CHNCXR_0098_0.png',\n",
              " 'CHNCXR_0099_0.png',\n",
              " 'CHNCXR_0100_0.png',\n",
              " 'CHNCXR_0101_0.png',\n",
              " 'CHNCXR_0102_0.png',\n",
              " 'CHNCXR_0103_0.png',\n",
              " 'CHNCXR_0104_0.png',\n",
              " 'CHNCXR_0105_0.png',\n",
              " 'CHNCXR_0106_0.png',\n",
              " 'CHNCXR_0107_0.png',\n",
              " 'CHNCXR_0108_0.png',\n",
              " 'CHNCXR_0109_0.png',\n",
              " 'CHNCXR_0110_0.png',\n",
              " 'CHNCXR_0111_0.png',\n",
              " 'CHNCXR_0112_0.png',\n",
              " 'CHNCXR_0113_0.png',\n",
              " 'CHNCXR_0114_0.png',\n",
              " 'CHNCXR_0115_0.png',\n",
              " 'CHNCXR_0116_0.png',\n",
              " 'CHNCXR_0117_0.png',\n",
              " 'CHNCXR_0118_0.png',\n",
              " 'CHNCXR_0119_0.png',\n",
              " 'CHNCXR_0120_0.png',\n",
              " 'CHNCXR_0121_0.png',\n",
              " 'CHNCXR_0122_0.png',\n",
              " 'CHNCXR_0123_0.png',\n",
              " 'CHNCXR_0124_0.png',\n",
              " 'CHNCXR_0125_0.png',\n",
              " 'CHNCXR_0126_0.png',\n",
              " 'CHNCXR_0127_0.png',\n",
              " 'CHNCXR_0128_0.png',\n",
              " 'CHNCXR_0129_0.png',\n",
              " 'CHNCXR_0130_0.png',\n",
              " 'CHNCXR_0131_0.png',\n",
              " 'CHNCXR_0132_0.png',\n",
              " 'CHNCXR_0133_0.png',\n",
              " 'CHNCXR_0134_0.png',\n",
              " 'CHNCXR_0135_0.png',\n",
              " 'CHNCXR_0136_0.png',\n",
              " 'CHNCXR_0137_0.png',\n",
              " 'CHNCXR_0138_0.png',\n",
              " 'CHNCXR_0139_0.png',\n",
              " 'CHNCXR_0140_0.png',\n",
              " 'CHNCXR_0141_0.png',\n",
              " 'CHNCXR_0142_0.png',\n",
              " 'CHNCXR_0143_0.png',\n",
              " 'CHNCXR_0144_0.png',\n",
              " 'CHNCXR_0145_0.png',\n",
              " 'CHNCXR_0146_0.png',\n",
              " 'CHNCXR_0147_0.png',\n",
              " 'CHNCXR_0148_0.png',\n",
              " 'CHNCXR_0149_0.png',\n",
              " 'CHNCXR_0150_0.png',\n",
              " 'CHNCXR_0151_0.png',\n",
              " 'CHNCXR_0152_0.png',\n",
              " 'CHNCXR_0153_0.png',\n",
              " 'CHNCXR_0154_0.png',\n",
              " 'CHNCXR_0155_0.png',\n",
              " 'CHNCXR_0156_0.png',\n",
              " 'CHNCXR_0157_0.png',\n",
              " 'CHNCXR_0158_0.png',\n",
              " 'CHNCXR_0159_0.png',\n",
              " 'CHNCXR_0160_0.png',\n",
              " 'CHNCXR_0161_0.png',\n",
              " 'CHNCXR_0162_0.png',\n",
              " 'CHNCXR_0163_0.png',\n",
              " 'CHNCXR_0164_0.png',\n",
              " 'CHNCXR_0165_0.png',\n",
              " 'CHNCXR_0166_0.png',\n",
              " 'CHNCXR_0167_0.png',\n",
              " 'CHNCXR_0168_0.png',\n",
              " 'CHNCXR_0169_0.png',\n",
              " 'CHNCXR_0170_0.png',\n",
              " 'CHNCXR_0171_0.png',\n",
              " 'CHNCXR_0172_0.png',\n",
              " 'CHNCXR_0173_0.png',\n",
              " 'CHNCXR_0174_0.png',\n",
              " 'CHNCXR_0175_0.png',\n",
              " 'CHNCXR_0176_0.png',\n",
              " 'CHNCXR_0177_0.png',\n",
              " 'CHNCXR_0178_0.png',\n",
              " 'CHNCXR_0179_0.png',\n",
              " 'CHNCXR_0180_0.png',\n",
              " 'CHNCXR_0221_0.png',\n",
              " 'CHNCXR_0222_0.png',\n",
              " 'CHNCXR_0223_0.png',\n",
              " 'CHNCXR_0224_0.png',\n",
              " 'CHNCXR_0225_0.png',\n",
              " 'CHNCXR_0226_0.png',\n",
              " 'CHNCXR_0227_0.png',\n",
              " 'CHNCXR_0228_0.png',\n",
              " 'CHNCXR_0229_0.png',\n",
              " 'CHNCXR_0230_0.png',\n",
              " 'CHNCXR_0231_0.png',\n",
              " 'CHNCXR_0232_0.png',\n",
              " 'CHNCXR_0233_0.png',\n",
              " 'CHNCXR_0234_0.png',\n",
              " 'CHNCXR_0235_0.png',\n",
              " 'CHNCXR_0236_0.png',\n",
              " 'CHNCXR_0237_0.png',\n",
              " 'CHNCXR_0238_0.png',\n",
              " 'CHNCXR_0239_0.png',\n",
              " 'CHNCXR_0240_0.png',\n",
              " 'CHNCXR_0241_0.png',\n",
              " 'CHNCXR_0242_0.png',\n",
              " 'CHNCXR_0243_0.png',\n",
              " 'CHNCXR_0244_0.png',\n",
              " 'CHNCXR_0245_0.png',\n",
              " 'CHNCXR_0246_0.png',\n",
              " 'CHNCXR_0247_0.png',\n",
              " 'CHNCXR_0248_0.png',\n",
              " 'CHNCXR_0249_0.png',\n",
              " 'CHNCXR_0250_0.png',\n",
              " 'CHNCXR_0251_0.png',\n",
              " 'CHNCXR_0252_0.png',\n",
              " 'CHNCXR_0253_0.png',\n",
              " 'CHNCXR_0254_0.png',\n",
              " 'CHNCXR_0255_0.png',\n",
              " 'CHNCXR_0256_0.png',\n",
              " 'CHNCXR_0257_0.png',\n",
              " 'CHNCXR_0258_0.png',\n",
              " 'CHNCXR_0259_0.png',\n",
              " 'CHNCXR_0260_0.png',\n",
              " 'CHNCXR_0261_0.png',\n",
              " 'CHNCXR_0262_0.png',\n",
              " 'CHNCXR_0263_0.png',\n",
              " 'CHNCXR_0264_0.png',\n",
              " 'CHNCXR_0265_0.png',\n",
              " 'CHNCXR_0266_0.png',\n",
              " 'CHNCXR_0267_0.png',\n",
              " 'CHNCXR_0268_0.png',\n",
              " 'CHNCXR_0269_0.png',\n",
              " 'CHNCXR_0270_0.png',\n",
              " 'CHNCXR_0271_0.png',\n",
              " 'CHNCXR_0272_0.png',\n",
              " 'CHNCXR_0273_0.png',\n",
              " 'CHNCXR_0274_0.png',\n",
              " 'CHNCXR_0275_0.png',\n",
              " 'CHNCXR_0276_0.png',\n",
              " 'CHNCXR_0277_0.png',\n",
              " 'CHNCXR_0278_0.png',\n",
              " 'CHNCXR_0279_0.png',\n",
              " 'CHNCXR_0280_0.png',\n",
              " 'CHNCXR_0281_0.png',\n",
              " 'CHNCXR_0282_0.png',\n",
              " 'CHNCXR_0283_0.png',\n",
              " 'CHNCXR_0284_0.png',\n",
              " 'CHNCXR_0285_0.png',\n",
              " 'CHNCXR_0286_0.png',\n",
              " 'CHNCXR_0287_0.png',\n",
              " 'CHNCXR_0288_0.png',\n",
              " 'CHNCXR_0289_0.png',\n",
              " 'CHNCXR_0290_0.png',\n",
              " 'CHNCXR_0291_0.png',\n",
              " 'CHNCXR_0292_0.png',\n",
              " 'CHNCXR_0293_0.png',\n",
              " 'CHNCXR_0294_0.png',\n",
              " 'CHNCXR_0295_0.png',\n",
              " 'CHNCXR_0296_0.png',\n",
              " 'CHNCXR_0297_0.png',\n",
              " 'CHNCXR_0298_0.png',\n",
              " 'CHNCXR_0299_0.png',\n",
              " 'CHNCXR_0300_0.png',\n",
              " 'CHNCXR_0301_0.png',\n",
              " 'CHNCXR_0302_0.png',\n",
              " 'CHNCXR_0303_0.png',\n",
              " 'CHNCXR_0304_0.png',\n",
              " 'CHNCXR_0305_0.png',\n",
              " 'CHNCXR_0306_0.png',\n",
              " 'CHNCXR_0307_0.png',\n",
              " 'CHNCXR_0308_0.png',\n",
              " 'CHNCXR_0309_0.png',\n",
              " 'CHNCXR_0310_0.png',\n",
              " 'CHNCXR_0311_0.png',\n",
              " 'CHNCXR_0312_0.png',\n",
              " 'CHNCXR_0313_0.png',\n",
              " 'CHNCXR_0314_0.png',\n",
              " 'CHNCXR_0315_0.png',\n",
              " 'CHNCXR_0316_0.png',\n",
              " 'CHNCXR_0317_0.png',\n",
              " 'CHNCXR_0318_0.png',\n",
              " 'CHNCXR_0319_0.png',\n",
              " 'CHNCXR_0320_0.png',\n",
              " 'CHNCXR_0321_0.png',\n",
              " 'CHNCXR_0322_0.png',\n",
              " 'CHNCXR_0323_0.png',\n",
              " 'CHNCXR_0324_0.png',\n",
              " 'CHNCXR_0325_0.png',\n",
              " 'CHNCXR_0326_0.png',\n",
              " 'CHNCXR_0327_1.png',\n",
              " 'CHNCXR_0328_1.png',\n",
              " 'CHNCXR_0329_1.png',\n",
              " 'CHNCXR_0330_1.png',\n",
              " 'CHNCXR_0331_1.png',\n",
              " 'CHNCXR_0332_1.png',\n",
              " 'CHNCXR_0333_1.png',\n",
              " 'CHNCXR_0334_1.png',\n",
              " 'CHNCXR_0335_1.png',\n",
              " 'CHNCXR_0337_1.png',\n",
              " 'CHNCXR_0338_1.png',\n",
              " 'CHNCXR_0339_1.png',\n",
              " 'CHNCXR_0340_1.png',\n",
              " 'CHNCXR_0361_1.png',\n",
              " 'CHNCXR_0362_1.png',\n",
              " 'CHNCXR_0363_1.png',\n",
              " 'CHNCXR_0364_1.png',\n",
              " 'CHNCXR_0365_1.png',\n",
              " 'CHNCXR_0366_1.png',\n",
              " 'CHNCXR_0367_1.png',\n",
              " 'CHNCXR_0368_1.png',\n",
              " 'CHNCXR_0369_1.png',\n",
              " 'CHNCXR_0370_1.png',\n",
              " 'CHNCXR_0371_1.png',\n",
              " 'CHNCXR_0372_1.png',\n",
              " 'CHNCXR_0373_1.png',\n",
              " 'CHNCXR_0374_1.png',\n",
              " 'CHNCXR_0375_1.png',\n",
              " 'CHNCXR_0376_1.png',\n",
              " 'CHNCXR_0377_1.png',\n",
              " 'CHNCXR_0378_1.png',\n",
              " 'CHNCXR_0379_1.png',\n",
              " 'CHNCXR_0380_1.png',\n",
              " 'CHNCXR_0381_1.png',\n",
              " 'CHNCXR_0382_1.png',\n",
              " 'CHNCXR_0383_1.png',\n",
              " 'CHNCXR_0384_1.png',\n",
              " 'CHNCXR_0385_1.png',\n",
              " 'CHNCXR_0386_1.png',\n",
              " 'CHNCXR_0387_1.png',\n",
              " 'CHNCXR_0388_1.png',\n",
              " 'CHNCXR_0389_1.png',\n",
              " 'CHNCXR_0390_1.png',\n",
              " 'CHNCXR_0391_1.png',\n",
              " 'CHNCXR_0392_1.png',\n",
              " 'CHNCXR_0393_1.png',\n",
              " 'CHNCXR_0394_1.png',\n",
              " 'CHNCXR_0395_1.png',\n",
              " 'CHNCXR_0396_1.png',\n",
              " 'CHNCXR_0397_1.png',\n",
              " 'CHNCXR_0398_1.png',\n",
              " 'CHNCXR_0399_1.png',\n",
              " 'CHNCXR_0400_1.png',\n",
              " 'CHNCXR_0401_1.png',\n",
              " 'CHNCXR_0402_1.png',\n",
              " 'CHNCXR_0403_1.png',\n",
              " 'CHNCXR_0404_1.png',\n",
              " 'CHNCXR_0405_1.png',\n",
              " 'CHNCXR_0406_1.png',\n",
              " 'CHNCXR_0407_1.png',\n",
              " 'CHNCXR_0408_1.png',\n",
              " 'CHNCXR_0409_1.png',\n",
              " 'CHNCXR_0410_1.png',\n",
              " 'CHNCXR_0411_1.png',\n",
              " 'CHNCXR_0412_1.png',\n",
              " 'CHNCXR_0413_1.png',\n",
              " 'CHNCXR_0414_1.png',\n",
              " 'CHNCXR_0415_1.png',\n",
              " 'CHNCXR_0416_1.png',\n",
              " 'CHNCXR_0417_1.png',\n",
              " 'CHNCXR_0418_1.png',\n",
              " 'CHNCXR_0419_1.png',\n",
              " 'CHNCXR_0420_1.png',\n",
              " 'CHNCXR_0421_1.png',\n",
              " 'CHNCXR_0422_1.png',\n",
              " 'CHNCXR_0423_1.png',\n",
              " 'CHNCXR_0424_1.png',\n",
              " 'CHNCXR_0425_1.png',\n",
              " 'CHNCXR_0426_1.png',\n",
              " 'CHNCXR_0427_1.png',\n",
              " 'CHNCXR_0428_1.png',\n",
              " 'CHNCXR_0429_1.png',\n",
              " 'CHNCXR_0430_1.png',\n",
              " 'CHNCXR_0431_1.png',\n",
              " 'CHNCXR_0432_1.png',\n",
              " 'CHNCXR_0433_1.png',\n",
              " 'CHNCXR_0434_1.png',\n",
              " 'CHNCXR_0435_1.png',\n",
              " 'CHNCXR_0436_1.png',\n",
              " 'CHNCXR_0437_1.png',\n",
              " 'CHNCXR_0438_1.png',\n",
              " 'CHNCXR_0439_1.png',\n",
              " 'CHNCXR_0440_1.png',\n",
              " 'CHNCXR_0441_1.png',\n",
              " 'CHNCXR_0442_1.png',\n",
              " 'CHNCXR_0443_1.png',\n",
              " 'CHNCXR_0444_1.png',\n",
              " 'CHNCXR_0445_1.png',\n",
              " 'CHNCXR_0446_1.png',\n",
              " 'CHNCXR_0447_1.png',\n",
              " 'CHNCXR_0448_1.png',\n",
              " 'CHNCXR_0449_1.png',\n",
              " 'CHNCXR_0450_1.png',\n",
              " 'CHNCXR_0451_1.png',\n",
              " 'CHNCXR_0452_1.png',\n",
              " 'CHNCXR_0453_1.png',\n",
              " 'CHNCXR_0454_1.png',\n",
              " 'CHNCXR_0455_1.png',\n",
              " 'CHNCXR_0456_1.png',\n",
              " 'CHNCXR_0457_1.png',\n",
              " 'CHNCXR_0458_1.png',\n",
              " 'CHNCXR_0459_1.png',\n",
              " 'CHNCXR_0460_1.png',\n",
              " 'CHNCXR_0461_1.png',\n",
              " 'CHNCXR_0462_1.png',\n",
              " 'CHNCXR_0463_1.png',\n",
              " 'CHNCXR_0464_1.png',\n",
              " 'CHNCXR_0465_1.png',\n",
              " 'CHNCXR_0466_1.png',\n",
              " 'CHNCXR_0467_1.png',\n",
              " 'CHNCXR_0468_1.png',\n",
              " 'CHNCXR_0469_1.png',\n",
              " 'CHNCXR_0470_1.png',\n",
              " 'CHNCXR_0471_1.png',\n",
              " 'CHNCXR_0472_1.png',\n",
              " 'CHNCXR_0473_1.png',\n",
              " 'CHNCXR_0474_1.png',\n",
              " 'CHNCXR_0475_1.png',\n",
              " 'CHNCXR_0476_1.png',\n",
              " 'CHNCXR_0477_1.png',\n",
              " 'CHNCXR_0478_1.png',\n",
              " 'CHNCXR_0479_1.png',\n",
              " 'CHNCXR_0480_1.png',\n",
              " 'CHNCXR_0501_1.png',\n",
              " 'CHNCXR_0503_1.png',\n",
              " 'CHNCXR_0504_1.png',\n",
              " 'CHNCXR_0506_1.png',\n",
              " 'CHNCXR_0507_1.png',\n",
              " 'CHNCXR_0508_1.png',\n",
              " 'CHNCXR_0509_1.png',\n",
              " 'CHNCXR_0510_1.png',\n",
              " 'CHNCXR_0511_1.png',\n",
              " 'CHNCXR_0512_1.png',\n",
              " 'CHNCXR_0513_1.png',\n",
              " 'CHNCXR_0514_1.png',\n",
              " 'CHNCXR_0515_1.png',\n",
              " 'CHNCXR_0516_1.png',\n",
              " 'CHNCXR_0517_1.png',\n",
              " 'CHNCXR_0518_1.png',\n",
              " 'CHNCXR_0519_1.png',\n",
              " 'CHNCXR_0520_1.png',\n",
              " 'CHNCXR_0521_1.png',\n",
              " 'CHNCXR_0522_1.png',\n",
              " 'CHNCXR_0523_1.png',\n",
              " 'CHNCXR_0524_1.png',\n",
              " 'CHNCXR_0525_1.png',\n",
              " 'CHNCXR_0526_1.png',\n",
              " 'CHNCXR_0527_1.png',\n",
              " 'CHNCXR_0528_1.png',\n",
              " 'CHNCXR_0529_1.png',\n",
              " 'CHNCXR_0530_1.png',\n",
              " 'CHNCXR_0531_1.png',\n",
              " 'CHNCXR_0532_1.png',\n",
              " 'CHNCXR_0533_1.png',\n",
              " 'CHNCXR_0534_1.png',\n",
              " 'CHNCXR_0535_1.png',\n",
              " 'CHNCXR_0536_1.png',\n",
              " 'CHNCXR_0537_1.png',\n",
              " 'CHNCXR_0538_1.png',\n",
              " 'CHNCXR_0539_1.png',\n",
              " 'CHNCXR_0540_1.png',\n",
              " 'CHNCXR_0541_1.png',\n",
              " 'CHNCXR_0542_1.png',\n",
              " 'CHNCXR_0543_1.png',\n",
              " 'CHNCXR_0544_1.png',\n",
              " 'CHNCXR_0545_1.png',\n",
              " 'CHNCXR_0546_1.png',\n",
              " 'CHNCXR_0547_1.png',\n",
              " 'CHNCXR_0548_1.png',\n",
              " 'CHNCXR_0549_1.png',\n",
              " 'CHNCXR_0550_1.png',\n",
              " 'CHNCXR_0551_1.png',\n",
              " 'CHNCXR_0552_1.png',\n",
              " 'CHNCXR_0553_1.png',\n",
              " 'CHNCXR_0554_1.png',\n",
              " 'CHNCXR_0555_1.png',\n",
              " 'CHNCXR_0556_1.png',\n",
              " 'CHNCXR_0557_1.png',\n",
              " 'CHNCXR_0558_1.png',\n",
              " 'CHNCXR_0559_1.png',\n",
              " 'CHNCXR_0566_1.png',\n",
              " 'CHNCXR_0567_1.png',\n",
              " 'CHNCXR_0568_1.png',\n",
              " 'CHNCXR_0569_1.png',\n",
              " 'CHNCXR_0570_1.png',\n",
              " 'CHNCXR_0571_1.png',\n",
              " 'CHNCXR_0572_1.png',\n",
              " 'CHNCXR_0573_1.png',\n",
              " 'CHNCXR_0574_1.png',\n",
              " 'CHNCXR_0575_1.png',\n",
              " 'CHNCXR_0576_1.png',\n",
              " 'CHNCXR_0577_1.png',\n",
              " 'CHNCXR_0578_1.png',\n",
              " 'CHNCXR_0579_1.png',\n",
              " 'CHNCXR_0580_1.png',\n",
              " 'CHNCXR_0581_1.png',\n",
              " 'CHNCXR_0582_1.png',\n",
              " 'CHNCXR_0583_1.png',\n",
              " 'CHNCXR_0584_1.png',\n",
              " 'CHNCXR_0585_1.png',\n",
              " 'CHNCXR_0586_1.png',\n",
              " 'CHNCXR_0587_1.png',\n",
              " 'CHNCXR_0588_1.png',\n",
              " 'CHNCXR_0589_1.png',\n",
              " 'CHNCXR_0590_1.png',\n",
              " 'CHNCXR_0591_1.png',\n",
              " 'CHNCXR_0592_1.png',\n",
              " 'CHNCXR_0593_1.png',\n",
              " 'CHNCXR_0594_1.png',\n",
              " 'CHNCXR_0595_1.png',\n",
              " 'CHNCXR_0596_1.png',\n",
              " 'CHNCXR_0597_1.png',\n",
              " 'CHNCXR_0598_1.png',\n",
              " 'CHNCXR_0599_1.png',\n",
              " 'CHNCXR_0600_1.png',\n",
              " 'CHNCXR_0601_1.png',\n",
              " 'CHNCXR_0602_1.png',\n",
              " 'CHNCXR_0603_1.png',\n",
              " 'CHNCXR_0604_1.png',\n",
              " 'CHNCXR_0605_1.png',\n",
              " 'CHNCXR_0606_1.png',\n",
              " 'CHNCXR_0607_1.png',\n",
              " 'CHNCXR_0608_1.png',\n",
              " 'CHNCXR_0609_1.png',\n",
              " 'CHNCXR_0610_1.png',\n",
              " 'CHNCXR_0611_1.png',\n",
              " 'CHNCXR_0612_1.png',\n",
              " 'CHNCXR_0613_1.png',\n",
              " 'CHNCXR_0614_1.png',\n",
              " 'CHNCXR_0615_1.png',\n",
              " 'CHNCXR_0616_1.png',\n",
              " 'CHNCXR_0617_1.png',\n",
              " 'CHNCXR_0618_1.png',\n",
              " 'CHNCXR_0619_1.png',\n",
              " 'CHNCXR_0620_1.png',\n",
              " 'CHNCXR_0621_1.png',\n",
              " 'CHNCXR_0622_1.png',\n",
              " 'CHNCXR_0623_1.png',\n",
              " 'CHNCXR_0624_1.png',\n",
              " 'CHNCXR_0625_1.png',\n",
              " 'CHNCXR_0626_1.png',\n",
              " 'CHNCXR_0627_1.png',\n",
              " 'CHNCXR_0628_1.png',\n",
              " 'CHNCXR_0629_1.png',\n",
              " 'CHNCXR_0630_1.png',\n",
              " 'CHNCXR_0631_1.png',\n",
              " 'CHNCXR_0632_1.png',\n",
              " 'CHNCXR_0633_1.png',\n",
              " 'CHNCXR_0634_1.png',\n",
              " 'CHNCXR_0635_1.png',\n",
              " 'CHNCXR_0636_1.png',\n",
              " 'CHNCXR_0637_1.png',\n",
              " 'CHNCXR_0638_1.png',\n",
              " 'CHNCXR_0639_1.png',\n",
              " 'CHNCXR_0640_1.png',\n",
              " 'CHNCXR_0641_1.png',\n",
              " 'CHNCXR_0642_1.png',\n",
              " 'CHNCXR_0643_1.png',\n",
              " 'CHNCXR_0644_1.png',\n",
              " 'CHNCXR_0645_1.png',\n",
              " 'CHNCXR_0646_1.png',\n",
              " 'CHNCXR_0647_1.png',\n",
              " 'CHNCXR_0648_1.png',\n",
              " 'CHNCXR_0649_1.png',\n",
              " 'CHNCXR_0650_1.png',\n",
              " 'CHNCXR_0651_1.png',\n",
              " 'CHNCXR_0652_1.png',\n",
              " 'CHNCXR_0653_1.png',\n",
              " 'CHNCXR_0654_1.png',\n",
              " 'CHNCXR_0655_1.png',\n",
              " 'CHNCXR_0656_1.png',\n",
              " 'CHNCXR_0657_1.png',\n",
              " 'CHNCXR_0658_1.png',\n",
              " 'CHNCXR_0659_1.png',\n",
              " 'CHNCXR_0660_1.png',\n",
              " 'CHNCXR_0661_1.png',\n",
              " 'CHNCXR_0662_1.png']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "xrays = []\n",
        "files = glob.glob('/content/drive/MyDrive/Lung_Seg/Masks/*.png')\n",
        "for file in files:\n",
        "  xrays.append(file[38:])\n",
        "xrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRWQHgtM03SJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606bffcf-b4c2-412d-e566-41d5631a2419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "951\n"
          ]
        }
      ],
      "source": [
        "print(len(xrays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs_DZHDMudzm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(1, len(xrays), 50):\n",
        "  for file in xrays[i:min(i+50, len(xrays))]:\n",
        "    image = cv2.imread('/content/drive/MyDrive/Lung_Seg/Model_Xrays/'+file)\n",
        "    mask = cv2.imread('/content/drive/MyDrive/Lung_Seg/Masks/'+file)\n",
        "    image = cv2.resize(image, (256, 256))\n",
        "    mask = cv2.resize(mask, (256, 256))\n",
        "    X.append(image)\n",
        "    Y.append(mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT5uTLtVzMth",
        "outputId": "4d70c4a0-07de-41ab-fc73-0a415b751f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "950\n",
            "950\n"
          ]
        }
      ],
      "source": [
        "print(len(X))\n",
        "print(len(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gosj6CTI31wL"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIra99J_39Dq"
      },
      "outputs": [],
      "source": [
        "X = X/255\n",
        "Y = Y/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgUzZntn7N5V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Dropout, GlobalMaxPooling2D,UpSampling2D, Input, Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y66X1xm5Ki9"
      },
      "outputs": [],
      "source": [
        "def conv_block(input, num_filters, times=2):\n",
        "  x = input\n",
        "  for i in range(times):\n",
        "    x = Conv2D(filters=num_filters, padding='same', kernel_size=3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "  \n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umtDPmCM8qta"
      },
      "outputs": [],
      "source": [
        "def encoder(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GtwuM6J8zSr"
      },
      "outputs": [],
      "source": [
        "def decoder(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI38SnZfAcs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62646e23-24e3-4412-eaca-307a4712b591"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'input_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "inputs = Input((256, 256, 3))\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "276jswji87zN"
      },
      "outputs": [],
      "source": [
        "s1, p1 = encoder(inputs, 64)\n",
        "s2, p2 = encoder(p1, 128)\n",
        "s3, p3 = encoder(p2, 256)\n",
        "s4, p4 = encoder(p3, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iP7hSgkAqZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d238cd-6981-4610-c834-40172f27dcfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 16, 16, 1024) dtype=float32 (created by layer 'activation_9')>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "b1 = conv_block(p4, 1024)\n",
        "b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR0_qSMTAtJu"
      },
      "outputs": [],
      "source": [
        "d1 = decoder(b1, s4, 512)\n",
        "d2 = decoder(d1, s3, 256)\n",
        "d3 = decoder(d2, s2, 128)\n",
        "d4 = decoder(d3, s1, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvPOmWwkGIXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d971cb-12b5-424e-c6da-d5853376d560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 256, 256, 64) dtype=float32 (created by layer 'activation_17')>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "d4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiULzfcPBImR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1620cc0-d1de-4f4b-8ed9-c3e6bfe90310"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 256, 256, 3) dtype=float32 (created by layer 'conv2d_18')>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "outputs = Conv2D(3, 3, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duNIldCuBNs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b25ba2a-9728-49fe-da2e-f7f59d91c297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 3)  1731        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,056,963\n",
            "Trainable params: 31,045,187\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        " model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        " model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as alb\n",
        "config = {\n",
        "    'augm_p_corrections': 0.3,\n",
        "    'augm_p_contrast': 1,\n",
        "    'augm_p_gamma': 1,\n",
        "    'augm_p_brightness': 1,\n",
        "\n",
        "    'augm_p_blurs': 0.5,\n",
        "    'augm_p_blur': 1,\n",
        "    'augm_p_motionblur': 0.5,\n",
        "    'augm_p_medianblur': 0.5,\n",
        "\n",
        "    'augm_p_distortions': 0.3,\n",
        "    'augm_p_elastic': 0.1,\n",
        "    'augm_p_grid': 0.1,\n",
        "    'augm_p_optical': 0.1,\n",
        "\n",
        "    'augm_p_shiftscalrot': 0.5,\n",
        "    'augm_shift_limit': 0.2,\n",
        "    'augm_scale_limit': 0.1,\n",
        "    'augm_rotate_limit': 8,\n",
        "}"
      ],
      "metadata": {
        "id": "OTuFe-8yzyxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augm = alb.Compose([\n",
        "        alb.OneOf([\n",
        "            alb.RandomContrast(p=config[\"augm_p_contrast\"]),\n",
        "            alb.RandomGamma(p=config[\"augm_p_gamma\"]),\n",
        "            alb.RandomBrightness(p=config[\"augm_p_brightness\"]),\n",
        "        ],\n",
        "            p=config[\"augm_p_corrections\"]),\n",
        "        alb.OneOf([\n",
        "            alb.Blur(blur_limit=4, p=config[\"augm_p_blur\"]),\n",
        "            alb.MotionBlur(blur_limit=4, p=config[\"augm_p_motionblur\"]),\n",
        "            alb.MedianBlur(blur_limit=4, p=config[\"augm_p_medianblur\"])\n",
        "        ],\n",
        "            p=config[\"augm_p_blurs\"]),\n",
        "        alb.OneOf([\n",
        "            alb.ElasticTransform(alpha=60,\n",
        "                                 sigma=60 * 0.20,\n",
        "                                 alpha_affine=60 * 0.03,\n",
        "                                 p=config[\"augm_p_elastic\"]),\n",
        "            alb.GridDistortion(p=config[\"augm_p_grid\"]),\n",
        "            alb.OpticalDistortion(\n",
        "                distort_limit=0.2, shift_limit=0.05, p=config[\"augm_p_optical\"]),\n",
        "        ],\n",
        "            p=config[\"augm_p_distortions\"])\n",
        "    ])"
      ],
      "metadata": {
        "id": "nxS1Qvf4zcC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJDHRqfZUGCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2f4ab3-4eb1-4189-ef41-93f9dc150619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(760, 256, 256, 3)\n",
            "(190, 256, 256, 3)\n",
            "(760, 256, 256, 3)\n",
            "(190, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4GC-nGuU9Qb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3678583-01a1-4986-b97c-6d5aeac0e258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(95, 256, 256, 3)\n",
            "(95, 256, 256, 3)\n",
            "(95, 256, 256, 3)\n",
            "(95, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_valid.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuYSHksHIqKl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98HokzvMBimK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzy2ACkHDmTS"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "lr = 1e-5\n",
        "num_epochs = 10\n",
        "model_path = \"/content/drive/MyDrive/Unet/model.h5\"\n",
        "csv_path = \"/content/drive/MyDrive/Unet/data.csv\"\n",
        "model.compile(optimizer=Adam(lr), loss=dice_loss, metrics=[iou, Recall(), Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10c93lwhED0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c402a57-6237-423e-c8ea-0b7a18c4e573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.4500 - iou: 0.3860 - recall: 0.9060 - precision: 0.5215\n",
            "Epoch 1: val_loss improved from inf to 0.56979, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 173s 987ms/step - loss: 0.4500 - iou: 0.3860 - recall: 0.9060 - precision: 0.5215 - val_loss: 0.5698 - val_iou: 0.2744 - val_recall: 1.0000 - val_precision: 0.2750 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.2448 - iou: 0.6087 - recall: 0.9689 - precision: 0.8747\n",
            "Epoch 2: val_loss improved from 0.56979 to 0.54633, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 139s 916ms/step - loss: 0.2448 - iou: 0.6087 - recall: 0.9689 - precision: 0.8747 - val_loss: 0.5463 - val_iou: 0.2937 - val_recall: 1.0000 - val_precision: 0.2868 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1781 - iou: 0.6984 - recall: 0.9687 - precision: 0.9261\n",
            "Epoch 3: val_loss improved from 0.54633 to 0.23311, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 917ms/step - loss: 0.1781 - iou: 0.6984 - recall: 0.9687 - precision: 0.9261 - val_loss: 0.2331 - val_iou: 0.6231 - val_recall: 0.9703 - val_precision: 0.8190 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1441 - iou: 0.7489 - recall: 0.9662 - precision: 0.9421\n",
            "Epoch 4: val_loss improved from 0.23311 to 0.13578, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 918ms/step - loss: 0.1441 - iou: 0.7489 - recall: 0.9662 - precision: 0.9421 - val_loss: 0.1358 - val_iou: 0.7613 - val_recall: 0.9738 - val_precision: 0.9381 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1187 - iou: 0.7883 - recall: 0.9670 - precision: 0.9506\n",
            "Epoch 5: val_loss improved from 0.13578 to 0.12018, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 924ms/step - loss: 0.1187 - iou: 0.7883 - recall: 0.9670 - precision: 0.9506 - val_loss: 0.1202 - val_iou: 0.7858 - val_recall: 0.9870 - val_precision: 0.9028 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1002 - iou: 0.8184 - recall: 0.9663 - precision: 0.9573\n",
            "Epoch 6: val_loss improved from 0.12018 to 0.08916, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 139s 916ms/step - loss: 0.1002 - iou: 0.8184 - recall: 0.9663 - precision: 0.9573 - val_loss: 0.0892 - val_iou: 0.8365 - val_recall: 0.9763 - val_precision: 0.9516 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0870 - iou: 0.8404 - recall: 0.9667 - precision: 0.9606\n",
            "Epoch 7: val_loss improved from 0.08916 to 0.08175, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 919ms/step - loss: 0.0870 - iou: 0.8404 - recall: 0.9667 - precision: 0.9606 - val_loss: 0.0817 - val_iou: 0.8490 - val_recall: 0.9647 - val_precision: 0.9685 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0771 - iou: 0.8572 - recall: 0.9656 - precision: 0.9645\n",
            "Epoch 8: val_loss improved from 0.08175 to 0.07058, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 918ms/step - loss: 0.0771 - iou: 0.8572 - recall: 0.9656 - precision: 0.9645 - val_loss: 0.0706 - val_iou: 0.8683 - val_recall: 0.9730 - val_precision: 0.9597 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0689 - iou: 0.8713 - recall: 0.9663 - precision: 0.9673\n",
            "Epoch 9: val_loss improved from 0.07058 to 0.06487, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 140s 923ms/step - loss: 0.0689 - iou: 0.8713 - recall: 0.9663 - precision: 0.9673 - val_loss: 0.0649 - val_iou: 0.8783 - val_recall: 0.9565 - val_precision: 0.9767 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0628 - iou: 0.8820 - recall: 0.9660 - precision: 0.9691\n",
            "Epoch 10: val_loss improved from 0.06487 to 0.05911, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 139s 917ms/step - loss: 0.0628 - iou: 0.8820 - recall: 0.9660 - precision: 0.9691 - val_loss: 0.0591 - val_iou: 0.8885 - val_recall: 0.9711 - val_precision: 0.9621 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0579 - iou: 0.8907 - recall: 0.9670 - precision: 0.9697\n",
            "Epoch 11: val_loss improved from 0.05911 to 0.05691, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 139s 917ms/step - loss: 0.0579 - iou: 0.8907 - recall: 0.9670 - precision: 0.9697 - val_loss: 0.0569 - val_iou: 0.8924 - val_recall: 0.9752 - val_precision: 0.9571 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0533 - iou: 0.8990 - recall: 0.9675 - precision: 0.9722\n",
            "Epoch 12: val_loss did not improve from 0.05691\n",
            "152/152 [==============================] - 135s 890ms/step - loss: 0.0533 - iou: 0.8990 - recall: 0.9675 - precision: 0.9722 - val_loss: 0.0571 - val_iou: 0.8922 - val_recall: 0.9802 - val_precision: 0.9463 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0492 - iou: 0.9064 - recall: 0.9684 - precision: 0.9736\n",
            "Epoch 13: val_loss improved from 0.05691 to 0.05016, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 141s 929ms/step - loss: 0.0492 - iou: 0.9064 - recall: 0.9684 - precision: 0.9736 - val_loss: 0.0502 - val_iou: 0.9046 - val_recall: 0.9716 - val_precision: 0.9645 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0463 - iou: 0.9116 - recall: 0.9687 - precision: 0.9743\n",
            "Epoch 14: val_loss improved from 0.05016 to 0.04727, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 933ms/step - loss: 0.0463 - iou: 0.9116 - recall: 0.9687 - precision: 0.9743 - val_loss: 0.0473 - val_iou: 0.9099 - val_recall: 0.9684 - val_precision: 0.9687 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0433 - iou: 0.9171 - recall: 0.9694 - precision: 0.9757\n",
            "Epoch 15: val_loss improved from 0.04727 to 0.04517, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 932ms/step - loss: 0.0433 - iou: 0.9171 - recall: 0.9694 - precision: 0.9757 - val_loss: 0.0452 - val_iou: 0.9137 - val_recall: 0.9690 - val_precision: 0.9675 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0406 - iou: 0.9220 - recall: 0.9705 - precision: 0.9766\n",
            "Epoch 16: val_loss did not improve from 0.04517\n",
            "152/152 [==============================] - 138s 907ms/step - loss: 0.0406 - iou: 0.9220 - recall: 0.9705 - precision: 0.9766 - val_loss: 0.0474 - val_iou: 0.9097 - val_recall: 0.9772 - val_precision: 0.9528 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0392 - iou: 0.9247 - recall: 0.9703 - precision: 0.9768\n",
            "Epoch 17: val_loss improved from 0.04517 to 0.04471, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 143s 941ms/step - loss: 0.0392 - iou: 0.9247 - recall: 0.9703 - precision: 0.9768 - val_loss: 0.0447 - val_iou: 0.9145 - val_recall: 0.9731 - val_precision: 0.9598 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0375 - iou: 0.9278 - recall: 0.9705 - precision: 0.9775\n",
            "Epoch 18: val_loss improved from 0.04471 to 0.04210, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0375 - iou: 0.9278 - recall: 0.9705 - precision: 0.9775 - val_loss: 0.0421 - val_iou: 0.9193 - val_recall: 0.9631 - val_precision: 0.9728 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0348 - iou: 0.9330 - recall: 0.9723 - precision: 0.9790\n",
            "Epoch 19: val_loss improved from 0.04210 to 0.04102, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 143s 937ms/step - loss: 0.0348 - iou: 0.9330 - recall: 0.9723 - precision: 0.9790 - val_loss: 0.0410 - val_iou: 0.9213 - val_recall: 0.9626 - val_precision: 0.9735 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0334 - iou: 0.9354 - recall: 0.9726 - precision: 0.9795\n",
            "Epoch 20: val_loss improved from 0.04102 to 0.04001, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0334 - iou: 0.9354 - recall: 0.9726 - precision: 0.9795 - val_loss: 0.0400 - val_iou: 0.9232 - val_recall: 0.9658 - val_precision: 0.9705 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0316 - iou: 0.9387 - recall: 0.9736 - precision: 0.9804\n",
            "Epoch 21: val_loss improved from 0.04001 to 0.03922, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 143s 942ms/step - loss: 0.0316 - iou: 0.9387 - recall: 0.9736 - precision: 0.9804 - val_loss: 0.0392 - val_iou: 0.9246 - val_recall: 0.9657 - val_precision: 0.9709 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0305 - iou: 0.9408 - recall: 0.9742 - precision: 0.9809\n",
            "Epoch 22: val_loss did not improve from 0.03922\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0305 - iou: 0.9408 - recall: 0.9742 - precision: 0.9809 - val_loss: 0.0393 - val_iou: 0.9246 - val_recall: 0.9623 - val_precision: 0.9730 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0293 - iou: 0.9432 - recall: 0.9749 - precision: 0.9815\n",
            "Epoch 23: val_loss improved from 0.03922 to 0.03819, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0293 - iou: 0.9432 - recall: 0.9749 - precision: 0.9815 - val_loss: 0.0382 - val_iou: 0.9265 - val_recall: 0.9661 - val_precision: 0.9701 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0277 - iou: 0.9463 - recall: 0.9760 - precision: 0.9824\n",
            "Epoch 24: val_loss improved from 0.03819 to 0.03817, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 933ms/step - loss: 0.0277 - iou: 0.9463 - recall: 0.9760 - precision: 0.9824 - val_loss: 0.0382 - val_iou: 0.9266 - val_recall: 0.9699 - val_precision: 0.9651 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0268 - iou: 0.9478 - recall: 0.9764 - precision: 0.9824\n",
            "Epoch 25: val_loss improved from 0.03817 to 0.03785, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 143s 943ms/step - loss: 0.0268 - iou: 0.9478 - recall: 0.9764 - precision: 0.9824 - val_loss: 0.0378 - val_iou: 0.9272 - val_recall: 0.9703 - val_precision: 0.9645 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0254 - iou: 0.9505 - recall: 0.9775 - precision: 0.9833\n",
            "Epoch 26: val_loss improved from 0.03785 to 0.03653, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0254 - iou: 0.9505 - recall: 0.9775 - precision: 0.9833 - val_loss: 0.0365 - val_iou: 0.9296 - val_recall: 0.9652 - val_precision: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0255 - iou: 0.9504 - recall: 0.9768 - precision: 0.9830\n",
            "Epoch 27: val_loss improved from 0.03653 to 0.03643, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0255 - iou: 0.9504 - recall: 0.9768 - precision: 0.9830 - val_loss: 0.0364 - val_iou: 0.9298 - val_recall: 0.9644 - val_precision: 0.9717 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0232 - iou: 0.9547 - recall: 0.9790 - precision: 0.9844\n",
            "Epoch 28: val_loss improved from 0.03643 to 0.03568, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 934ms/step - loss: 0.0232 - iou: 0.9547 - recall: 0.9790 - precision: 0.9844 - val_loss: 0.0357 - val_iou: 0.9312 - val_recall: 0.9638 - val_precision: 0.9730 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0230 - iou: 0.9552 - recall: 0.9791 - precision: 0.9842\n",
            "Epoch 29: val_loss did not improve from 0.03568\n",
            "152/152 [==============================] - 139s 915ms/step - loss: 0.0230 - iou: 0.9552 - recall: 0.9791 - precision: 0.9842 - val_loss: 0.0364 - val_iou: 0.9298 - val_recall: 0.9694 - val_precision: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0223 - iou: 0.9565 - recall: 0.9795 - precision: 0.9844\n",
            "Epoch 30: val_loss did not improve from 0.03568\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0223 - iou: 0.9565 - recall: 0.9795 - precision: 0.9844 - val_loss: 0.0360 - val_iou: 0.9306 - val_recall: 0.9716 - val_precision: 0.9633 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0207 - iou: 0.9595 - recall: 0.9810 - precision: 0.9855\n",
            "Epoch 31: val_loss improved from 0.03568 to 0.03512, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 933ms/step - loss: 0.0207 - iou: 0.9595 - recall: 0.9810 - precision: 0.9855 - val_loss: 0.0351 - val_iou: 0.9323 - val_recall: 0.9630 - val_precision: 0.9731 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0202 - iou: 0.9604 - recall: 0.9811 - precision: 0.9857\n",
            "Epoch 32: val_loss did not improve from 0.03512\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0202 - iou: 0.9604 - recall: 0.9811 - precision: 0.9857 - val_loss: 0.0353 - val_iou: 0.9320 - val_recall: 0.9659 - val_precision: 0.9695 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0198 - iou: 0.9612 - recall: 0.9815 - precision: 0.9857\n",
            "Epoch 33: val_loss did not improve from 0.03512\n",
            "152/152 [==============================] - 139s 915ms/step - loss: 0.0198 - iou: 0.9612 - recall: 0.9815 - precision: 0.9857 - val_loss: 0.0354 - val_iou: 0.9318 - val_recall: 0.9700 - val_precision: 0.9651 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0188 - iou: 0.9631 - recall: 0.9823 - precision: 0.9865\n",
            "Epoch 34: val_loss improved from 0.03512 to 0.03404, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 143s 941ms/step - loss: 0.0188 - iou: 0.9631 - recall: 0.9823 - precision: 0.9865 - val_loss: 0.0340 - val_iou: 0.9343 - val_recall: 0.9637 - val_precision: 0.9732 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0187 - iou: 0.9633 - recall: 0.9822 - precision: 0.9863\n",
            "Epoch 35: val_loss did not improve from 0.03404\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0187 - iou: 0.9633 - recall: 0.9822 - precision: 0.9863 - val_loss: 0.0341 - val_iou: 0.9341 - val_recall: 0.9696 - val_precision: 0.9673 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0178 - iou: 0.9650 - recall: 0.9830 - precision: 0.9868\n",
            "Epoch 36: val_loss improved from 0.03404 to 0.03374, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 931ms/step - loss: 0.0178 - iou: 0.9650 - recall: 0.9830 - precision: 0.9868 - val_loss: 0.0337 - val_iou: 0.9348 - val_recall: 0.9684 - val_precision: 0.9685 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0173 - iou: 0.9660 - recall: 0.9833 - precision: 0.9873\n",
            "Epoch 37: val_loss did not improve from 0.03374\n",
            "152/152 [==============================] - 139s 914ms/step - loss: 0.0173 - iou: 0.9660 - recall: 0.9833 - precision: 0.9873 - val_loss: 0.0371 - val_iou: 0.9286 - val_recall: 0.9754 - val_precision: 0.9551 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0168 - iou: 0.9669 - recall: 0.9839 - precision: 0.9873\n",
            "Epoch 38: val_loss improved from 0.03374 to 0.03310, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 937ms/step - loss: 0.0168 - iou: 0.9669 - recall: 0.9839 - precision: 0.9873 - val_loss: 0.0331 - val_iou: 0.9360 - val_recall: 0.9627 - val_precision: 0.9749 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0168 - iou: 0.9670 - recall: 0.9836 - precision: 0.9874\n",
            "Epoch 39: val_loss did not improve from 0.03310\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0168 - iou: 0.9670 - recall: 0.9836 - precision: 0.9874 - val_loss: 0.0352 - val_iou: 0.9322 - val_recall: 0.9648 - val_precision: 0.9687 - lr: 1.0000e-05\n",
            "Epoch 40/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0162 - iou: 0.9682 - recall: 0.9843 - precision: 0.9877\n",
            "Epoch 40: val_loss did not improve from 0.03310\n",
            "152/152 [==============================] - 138s 907ms/step - loss: 0.0162 - iou: 0.9682 - recall: 0.9843 - precision: 0.9877 - val_loss: 0.0340 - val_iou: 0.9343 - val_recall: 0.9666 - val_precision: 0.9690 - lr: 1.0000e-05\n",
            "Epoch 41/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0151 - iou: 0.9703 - recall: 0.9853 - precision: 0.9886\n",
            "Epoch 41: val_loss did not improve from 0.03310\n",
            "152/152 [==============================] - 139s 915ms/step - loss: 0.0151 - iou: 0.9703 - recall: 0.9853 - precision: 0.9886 - val_loss: 0.0340 - val_iou: 0.9344 - val_recall: 0.9597 - val_precision: 0.9757 - lr: 1.0000e-05\n",
            "Epoch 42/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0151 - iou: 0.9703 - recall: 0.9852 - precision: 0.9884\n",
            "Epoch 42: val_loss improved from 0.03310 to 0.03278, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 142s 933ms/step - loss: 0.0151 - iou: 0.9703 - recall: 0.9852 - precision: 0.9884 - val_loss: 0.0328 - val_iou: 0.9366 - val_recall: 0.9649 - val_precision: 0.9726 - lr: 1.0000e-05\n",
            "Epoch 43/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0150 - iou: 0.9704 - recall: 0.9852 - precision: 0.9884\n",
            "Epoch 43: val_loss did not improve from 0.03278\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0150 - iou: 0.9704 - recall: 0.9852 - precision: 0.9884 - val_loss: 0.0336 - val_iou: 0.9350 - val_recall: 0.9706 - val_precision: 0.9654 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0143 - iou: 0.9719 - recall: 0.9857 - precision: 0.9891\n",
            "Epoch 44: val_loss did not improve from 0.03278\n",
            "152/152 [==============================] - 138s 908ms/step - loss: 0.0143 - iou: 0.9719 - recall: 0.9857 - precision: 0.9891 - val_loss: 0.0363 - val_iou: 0.9301 - val_recall: 0.9651 - val_precision: 0.9650 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0143 - iou: 0.9718 - recall: 0.9857 - precision: 0.9887\n",
            "Epoch 45: val_loss did not improve from 0.03278\n",
            "152/152 [==============================] - 139s 915ms/step - loss: 0.0143 - iou: 0.9718 - recall: 0.9857 - precision: 0.9887 - val_loss: 0.0334 - val_iou: 0.9355 - val_recall: 0.9670 - val_precision: 0.9688 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            " 10/152 [>.............................] - ETA: 2:02 - loss: 0.0134 - iou: 0.9735 - recall: 0.9856 - precision: 0.9905"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-576d66023cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "             ModelCheckpoint(\"/content/drive/MyDrive/Unet/model.h5\", verbose=1, save_best_only=True),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "             CSVLogger(csv_path)\n",
        "]\n",
        "history = model.fit(X_train, Y_train, batch_size=5, shuffle=True, validation_data=(X_valid, Y_valid), callbacks=callbacks, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feAOZj0VEmGo",
        "outputId": "5d34948f-992b-409a-8698-8fdbdd1e9984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0104 - iou: 0.9794 - recall: 0.9903 - precision: 0.9928\n",
            "Epoch 61: val_loss improved from 0.02216 to 0.02212, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "92/92 [==============================] - 89s 968ms/step - loss: 0.0104 - iou: 0.9794 - recall: 0.9903 - precision: 0.9928 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9798 - val_precision: 0.9789 - lr: 1.0000e-07\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0105 - iou: 0.9793 - recall: 0.9903 - precision: 0.9927\n",
            "Epoch 62: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 85s 918ms/step - loss: 0.0105 - iou: 0.9793 - recall: 0.9903 - precision: 0.9927 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9799 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0105 - iou: 0.9792 - recall: 0.9903 - precision: 0.9928\n",
            "Epoch 63: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 85s 920ms/step - loss: 0.0105 - iou: 0.9792 - recall: 0.9903 - precision: 0.9928 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9799 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0104 - iou: 0.9795 - recall: 0.9905 - precision: 0.9928\n",
            "Epoch 64: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0104 - iou: 0.9795 - recall: 0.9905 - precision: 0.9928 - val_loss: 0.0222 - val_iou: 0.9572 - val_recall: 0.9799 - val_precision: 0.9787 - lr: 1.0000e-07\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0107 - iou: 0.9788 - recall: 0.9900 - precision: 0.9927\n",
            "Epoch 65: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 85s 919ms/step - loss: 0.0107 - iou: 0.9788 - recall: 0.9900 - precision: 0.9927 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9798 - val_precision: 0.9789 - lr: 1.0000e-07\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0107 - iou: 0.9788 - recall: 0.9900 - precision: 0.9926\n",
            "Epoch 66: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0107 - iou: 0.9788 - recall: 0.9900 - precision: 0.9926 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9801 - val_precision: 0.9786 - lr: 1.0000e-07\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0109 - iou: 0.9785 - recall: 0.9900 - precision: 0.9922\n",
            "Epoch 67: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 85s 921ms/step - loss: 0.0109 - iou: 0.9785 - recall: 0.9900 - precision: 0.9922 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9800 - val_precision: 0.9787 - lr: 1.0000e-07\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0109 - iou: 0.9785 - recall: 0.9900 - precision: 0.9923\n",
            "Epoch 68: val_loss did not improve from 0.02212\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0109 - iou: 0.9785 - recall: 0.9900 - precision: 0.9923 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9799 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0106 - iou: 0.9790 - recall: 0.9903 - precision: 0.9924\n",
            "Epoch 69: val_loss improved from 0.02212 to 0.02211, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "92/92 [==============================] - 89s 965ms/step - loss: 0.0106 - iou: 0.9790 - recall: 0.9903 - precision: 0.9924 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9798 - val_precision: 0.9789 - lr: 1.0000e-07\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0108 - iou: 0.9787 - recall: 0.9899 - precision: 0.9926\n",
            "Epoch 70: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 85s 918ms/step - loss: 0.0108 - iou: 0.9787 - recall: 0.9899 - precision: 0.9926 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9800 - val_precision: 0.9787 - lr: 1.0000e-07\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0102 - iou: 0.9797 - recall: 0.9907 - precision: 0.9929\n",
            "Epoch 71: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 85s 921ms/step - loss: 0.0102 - iou: 0.9797 - recall: 0.9907 - precision: 0.9929 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9801 - val_precision: 0.9786 - lr: 1.0000e-07\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0107 - iou: 0.9789 - recall: 0.9902 - precision: 0.9926\n",
            "Epoch 72: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0107 - iou: 0.9789 - recall: 0.9902 - precision: 0.9926 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9800 - val_precision: 0.9787 - lr: 1.0000e-07\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0106 - iou: 0.9790 - recall: 0.9901 - precision: 0.9929\n",
            "Epoch 73: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 85s 920ms/step - loss: 0.0106 - iou: 0.9790 - recall: 0.9901 - precision: 0.9929 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9800 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0105 - iou: 0.9792 - recall: 0.9902 - precision: 0.9927\n",
            "Epoch 74: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0105 - iou: 0.9792 - recall: 0.9902 - precision: 0.9927 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9798 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0103 - iou: 0.9797 - recall: 0.9905 - precision: 0.9929\n",
            "Epoch 75: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 85s 921ms/step - loss: 0.0103 - iou: 0.9797 - recall: 0.9905 - precision: 0.9929 - val_loss: 0.0222 - val_iou: 0.9572 - val_recall: 0.9799 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0107 - iou: 0.9789 - recall: 0.9903 - precision: 0.9926\n",
            "Epoch 76: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0107 - iou: 0.9789 - recall: 0.9903 - precision: 0.9926 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9798 - val_precision: 0.9789 - lr: 1.0000e-07\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0107 - iou: 0.9789 - recall: 0.9900 - precision: 0.9927\n",
            "Epoch 77: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 85s 921ms/step - loss: 0.0107 - iou: 0.9789 - recall: 0.9900 - precision: 0.9927 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9799 - val_precision: 0.9788 - lr: 1.0000e-07\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0106 - iou: 0.9791 - recall: 0.9900 - precision: 0.9928\n",
            "Epoch 78: val_loss did not improve from 0.02211\n",
            "92/92 [==============================] - 84s 917ms/step - loss: 0.0106 - iou: 0.9791 - recall: 0.9900 - precision: 0.9928 - val_loss: 0.0221 - val_iou: 0.9573 - val_recall: 0.9801 - val_precision: 0.9786 - lr: 1.0000e-07\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0106 - iou: 0.9790 - recall: 0.9904 - precision: 0.9926"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, batch_size=5, shuffle=True, validation_data=(X_valid, Y_valid), callbacks=callbacks, epochs=100, initial_epoch=60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(X[0]*255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "ZVzYp8gWIg5q",
        "outputId": "74fe6c32-961e-4cb1-a7bb-1ad34698a784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F6636727FD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "6bAkCcgXPAGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uxFev3bTjhq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-q1CTB1EcR0",
        "outputId": "6bc18292-233e-4454-aee4-3fc32e9a2de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - ETA: 0s - loss: 0.4554 - iou: 0.3816 - recall: 0.8758 - precision: 0.5039 \n",
            "Epoch 1: val_loss improved from inf to 0.54904, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 4952s 33s/step - loss: 0.4554 - iou: 0.3816 - recall: 0.8758 - precision: 0.5039 - val_loss: 0.5490 - val_iou: 0.2915 - val_recall: 1.0000 - val_precision: 0.2787 - lr: 1.0000e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f885c1f18d0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks = [\n",
        "             ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "             CSVLogger(csv_path)\n",
        "]\n",
        "model.fit(X_train, Y_train, batch_size=5, shuffle=True, validation_data=(X_valid, Y_valid), callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-UJcRzPkLt3",
        "outputId": "ccf3163a-f2a5-4db0-fec1-344bd3d30218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.2600 - iou: 0.5889 - recall: 0.9711 - precision: 0.8586 \n",
            "Epoch 2: val_loss improved from 0.54904 to 0.51768, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 4562s 30s/step - loss: 0.2600 - iou: 0.5889 - recall: 0.9711 - precision: 0.8586 - val_loss: 0.5177 - val_iou: 0.3183 - val_recall: 0.9997 - val_precision: 0.3164 - lr: 1.0000e-05\n",
            "Epoch 3/10\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1951 - iou: 0.6745 - recall: 0.9727 - precision: 0.9129 \n",
            "Epoch 3: val_loss improved from 0.51768 to 0.21055, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 4408s 29s/step - loss: 0.1951 - iou: 0.6745 - recall: 0.9727 - precision: 0.9129 - val_loss: 0.2106 - val_iou: 0.6526 - val_recall: 0.9405 - val_precision: 0.9154 - lr: 1.0000e-05\n",
            "Epoch 4/10\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.1567 - iou: 0.7300 - recall: 0.9709 - precision: 0.9318 \n",
            "Epoch 4: val_loss improved from 0.21055 to 0.15137, saving model to /content/drive/MyDrive/Unet/model.h5\n",
            "152/152 [==============================] - 4254s 28s/step - loss: 0.1567 - iou: 0.7300 - recall: 0.9709 - precision: 0.9318 - val_loss: 0.1514 - val_iou: 0.7375 - val_recall: 0.9592 - val_precision: 0.9477 - lr: 1.0000e-05\n",
            "Epoch 5/10\n",
            " 31/152 [=====>........................] - ETA: 54:02 - loss: 0.1406 - iou: 0.7545 - recall: 0.9715 - precision: 0.9397"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, batch_size=5, shuffle=True, validation_data=(X_valid, Y_valid), callbacks=callbacks, epochs=num_epochs, initial_epoch=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}